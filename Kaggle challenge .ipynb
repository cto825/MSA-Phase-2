{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cathe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\cathe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "re.compile('<title>(.*)</title>')\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Kaggle-Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping any null values in text\n",
    "train.dropna(subset=['text'],inplace=True)\n",
    "train = train[train.text != '']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove punctuation\n",
    "train.text = train.text.apply(lambda x: re.sub(r'[^\\w\\s]', '', x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove stopword\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords = stopwords.words('english')\n",
    "train.text = train.text.apply(lambda x: ' '.join([word for word in nltk.word_tokenize(x) if word.lower() not in stopwords]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove link\n",
    "train.text = train.text.apply(lambda x: re.sub(r'\\(?http\\S+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing words\n",
    "#Stemming is normalizing the word by chopping the end of the word which is not always useful, hence we use lemmatization instead\n",
    "\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "train.text = train.text.apply(lambda x: ' '.join( [lemmatizer.lemmatize(word) for word in nltk.word_tokenize(x)]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Countvectorise() transform the text to training matrix which we use for machine learning\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(train.text) #we use fit_transform to transfrom text to document-term matrix(DTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('cleanedTrain.csv',index=False) #export trainning dataset to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>Id responded going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD miss San Diego</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>bos bullying</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>interview leave alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons couldnt put release already bought</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28b57f3990</td>\n",
       "      <td>shameless plugging best Rangers forum earth</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6e0c6d75b1</td>\n",
       "      <td>2am feeding baby fun smile coo</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50e14c0bb8</td>\n",
       "      <td>Soooo high</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e050245fbd</td>\n",
       "      <td></td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fc2cbefa9d</td>\n",
       "      <td>Journey Wow u became cooler hehe possible</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                         text sentiment\n",
       "0  cb774db0d1                           Id responded going   neutral\n",
       "1  549e992a42                      Sooo SAD miss San Diego  negative\n",
       "2  088c60f138                                 bos bullying  negative\n",
       "3  9642c003ef                        interview leave alone  negative\n",
       "4  358bd9e861      Sons couldnt put release already bought  negative\n",
       "5  28b57f3990  shameless plugging best Rangers forum earth   neutral\n",
       "6  6e0c6d75b1               2am feeding baby fun smile coo  positive\n",
       "7  50e14c0bb8                                   Soooo high   neutral\n",
       "8  e050245fbd                                                neutral\n",
       "9  fc2cbefa9d    Journey Wow u became cooler hehe possible  positive"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Building and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb=MultinomialNB()\n",
    "nb.fit(X_train,train.sentiment) #training the model with the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>726e501993</td>\n",
       "      <td>that`s great!! weee!! visitors!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>261932614e</td>\n",
       "      <td>I THINK EVERYONE HATES ME ON HERE   lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>afa11da83f</td>\n",
       "      <td>soooooo wish i could, but im in school and my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e64208b4ef</td>\n",
       "      <td>and within a short time of the last clue all ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>37bcad24ca</td>\n",
       "      <td>What did you get?  My day is alright.. haven`...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text\n",
       "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh\n",
       "1  96d74cb729   Shanghai is also really exciting (precisely -...\n",
       "2  eee518ae67  Recession hit Veronique Branquinho, she has to...\n",
       "3  01082688c6                                        happy bday!\n",
       "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!\n",
       "5  726e501993                    that`s great!! weee!! visitors!\n",
       "6  261932614e            I THINK EVERYONE HATES ME ON HERE   lol\n",
       "7  afa11da83f   soooooo wish i could, but im in school and my...\n",
       "8  e64208b4ef   and within a short time of the last clue all ...\n",
       "9  37bcad24ca   What did you get?  My day is alright.. haven`..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading in and cleaning test dataset\n",
    "test = pd.read_csv('test.csv')\n",
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dropna(subset=['text'],inplace=True)\n",
    "test = test[test.text != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.text = test.text.apply(lambda x: re.sub(r'[^\\w\\s]', '', x) ) #get rid of symbol "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "test.text = test.text.apply(lambda x: ' '.join([word for word in nltk.word_tokenize(x) if word.lower() not in stopwords]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.text = test.text.apply(lambda x: re.sub(r'\\(?http\\S+', '', x)) #get rid of http/website link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatization(Normalisation)is betterthan Stemming  \n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "test.text = test.text.apply(lambda x: ' '.join( [lemmatizer.lemmatize(word) for word in nltk.word_tokenize(x)]) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform(test.text) \n",
    "#we use 'transform' to transform text to DTM, we don't use fit_transform as it will lead to overfitting in the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform prediction using the trained model\n",
    "predicted = list(nb.predict(X_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Sentiment'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session day</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai also really exciting precisely skyscr...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho quit compan...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>like</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>726e501993</td>\n",
       "      <td>thats great weee visitor</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>261932614e</td>\n",
       "      <td>THINK EVERYONE HATES lol</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>afa11da83f</td>\n",
       "      <td>soooooo wish could im school myspace completel...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e64208b4ef</td>\n",
       "      <td>within short time last clue</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>37bcad24ca</td>\n",
       "      <td>get day alright havent done anything yet leavi...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text Sentiment\n",
       "0  f87dea47db                                   Last session day  positive\n",
       "1  96d74cb729  Shanghai also really exciting precisely skyscr...  positive\n",
       "2  eee518ae67  Recession hit Veronique Branquinho quit compan...  negative\n",
       "3  01082688c6                                         happy bday  positive\n",
       "4  33987a8ee5                                               like   neutral\n",
       "5  726e501993                           thats great weee visitor  positive\n",
       "6  261932614e                           THINK EVERYONE HATES lol  negative\n",
       "7  afa11da83f  soooooo wish could im school myspace completel...  negative\n",
       "8  e64208b4ef                        within short time last clue   neutral\n",
       "9  37bcad24ca  get day alright havent done anything yet leavi...   neutral"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=test.drop('text',axis=1) #drop column text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('test-Kaggle.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the trained model on the business dataset and perform sentiment predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the business dataset and called it Uber\n",
    "Uber = pd.read_csv('comments1.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "Uber.Reply = Uber.Reply.apply(lambda x: re.sub(r'[^\\w\\s]', '', x)) #getting rid of symbol "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One of the major forms of pre-processing is to filter out useless data\n",
    "#getting rid of English stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "Uber.Reply = Uber.Reply.apply(lambda x: ' '.join([word for word in nltk.word_tokenize(x) if word.lower() not in stopwords]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reply = vectorizer.transform(Uber.Reply) #transforming reply to document-term matrix\n",
    "prediction = nb.predict(Reply) #predict sentiment using the trained model\n",
    "Uber['Sentiment']=prediction #create a new column called Sentiment and store prediction in the new column\n",
    "Uber.to_csv('Uber.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reply</th>\n",
       "      <th>Upvote</th>\n",
       "      <th>Time</th>\n",
       "      <th>Key</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Write letter Uber 1455 Market St 400 San Franc...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2020-09-17 03:23:49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forgot password Fix</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2020-09-17 04:26:58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>contact support actually dealing Uber employee...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-09-17 02:11:08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.4092</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fuck Uber</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-09-17 11:35:02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5423</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>could take account delete</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-09-17 12:04:59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>still lost lmao</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-09-15 14:17:07</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Everyhing either emits electromagnetic energy ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-09-15 14:22:18</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.4854</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>things detected far far sway magnetically</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-09-15 14:54:41</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>look remote sensing</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-09-15 14:58:10</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Please teach remote sense wan na remote sense ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-09-15 15:00:08</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Reply  Upvote  \\\n",
       "0   Write letter Uber 1455 Market St 400 San Franc...     4.0   \n",
       "1                                 Forgot password Fix     3.0   \n",
       "2   contact support actually dealing Uber employee...     2.0   \n",
       "3                                           Fuck Uber     1.0   \n",
       "4                           could take account delete     1.0   \n",
       "..                                                ...     ...   \n",
       "95                                    still lost lmao     1.0   \n",
       "96  Everyhing either emits electromagnetic energy ...     2.0   \n",
       "97          things detected far far sway magnetically     1.0   \n",
       "98                                look remote sensing     2.0   \n",
       "99  Please teach remote sense wan na remote sense ...     1.0   \n",
       "\n",
       "                   Time   Key    neg    neu    pos  compound Sentiment  \n",
       "0   2020-09-17 03:23:49   0.0  0.000  1.000  0.000    0.0000   neutral  \n",
       "1   2020-09-17 04:26:58   0.0  0.000  1.000  0.000    0.0000  negative  \n",
       "2   2020-09-17 02:11:08   0.0  0.057  0.910  0.033   -0.4092  negative  \n",
       "3   2020-09-17 11:35:02   0.0  0.778  0.222  0.000   -0.5423  positive  \n",
       "4   2020-09-17 12:04:59   0.0  0.000  1.000  0.000    0.0000   neutral  \n",
       "..                  ...   ...    ...    ...    ...       ...       ...  \n",
       "95  2020-09-15 14:17:07  19.0  0.280  0.244  0.476    0.3818  negative  \n",
       "96  2020-09-15 14:22:18  19.0  0.000  0.908  0.092    0.4854  positive  \n",
       "97  2020-09-15 14:54:41  19.0  0.000  1.000  0.000    0.0000   neutral  \n",
       "98  2020-09-15 14:58:10  19.0  0.000  1.000  0.000    0.0000  positive  \n",
       "99  2020-09-15 15:00:08  19.0  0.000  0.850  0.150    0.3182  positive  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Uber.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492 1485\n"
     ]
    }
   ],
   "source": [
    "#The number of matching values and mismatch values between Naive Bayes and Textblob\n",
    "match = 0\n",
    "mismatch = 0\n",
    "#neutral = 0\n",
    "\n",
    "for i in range(len(Uber)):\n",
    "    if (Uber.compound.iloc[i] < 0  and  Uber.Sentiment.iloc[i] == \"negative\"):\n",
    "        match += 1\n",
    "    elif (Uber.compound.iloc[i] > 0 and Uber.Sentiment.iloc[i] == \"positive\"):\n",
    "        match += 1\n",
    "    elif (Uber.compound.iloc[i] == 0 and Uber.Sentiment.iloc ==\"neutral\"):\n",
    "        match +=1\n",
    "    else:\n",
    "        mismatch += 1\n",
    "\n",
    "print(match, mismatch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is there a difference between Naive Bayes model and Vader?\n",
    "\n",
    "It shows that here are 492 pairs of matching predictions and 1485 pairs of mismatch prediction between Naive Bayes model and Vader.\n",
    "The difference exists because Vader has been trained on numerous amount of data, whereas the NB model we built has only been trained on 20000 plus rows of data. Additionally, the Kaggle data we used to train the model has a different context to the Reddit data we collected which explains why there is a difference in the sentiment analysis between Naive Bayes and Vader. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
